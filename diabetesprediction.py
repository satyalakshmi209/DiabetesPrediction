# -*- coding: utf-8 -*-
"""diabetesprediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UbgbDcQ9abz8CulPWtI2XEIcSuXKnaFe
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

file_path = input("Enter the path to the CSV file: ")
df = pd.read_csv(file_path)

# Display the first few rows of the dataset
print(df.head())

# Check for missing values
print(df.isnull().sum())

# Display summary statistics
print(df.describe())

# Plot histograms for each feature
df.hist(bins=15, figsize=(15, 10))
plt.show()

# Check the distribution of the target variable
sns.countplot(x='Outcome', data=df)
plt.show()

# Handle missing values (optional, depending on your data)
# For example, replacing zeros with the median for certain columns
df['Glucose'].replace(0, df['Glucose'].median(), inplace=True)
df['BloodPressure'].replace(0, df['BloodPressure'].median(), inplace=True)
df['SkinThickness'].replace(0, df['SkinThickness'].median(), inplace=True)
df['Insulin'].replace(0, df['Insulin'].median(), inplace=True)
df['BMI'].replace(0, df['BMI'].median(), inplace=True)

# Split the data into features and target variable
X = df.drop(columns='Outcome')
y = df['Outcome']

# Scale the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Compute the correlation matrix
correlation_matrix = df.corr()

# Display the correlation matrix
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Logistic Regression
lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)
lr_predictions = lr_model.predict(X_test)

# Evaluate Logistic Regression
print("Logistic Regression Accuracy:", accuracy_score(y_test, lr_predictions))
print(confusion_matrix(y_test, lr_predictions))
print(classification_report(y_test, lr_predictions))

# Predict the outcomes on the test set
lr_predictions = lr_model.predict(X_test)

# Accuracy
accuracy = accuracy_score(y_test, lr_predictions)
print("Logistic Regression Accuracy:", accuracy)

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, lr_predictions)
print("Confusion Matrix:")
print(conf_matrix)

# Classification Report
class_report = classification_report(y_test, lr_predictions)
print("Classification Report:")
print(class_report)

# Plot the confusion matrix
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

# Define the parameter grid
param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],
    'penalty': ['l1', 'l2', 'elasticnet', 'none'],  # Note: 'elasticnet' requires the saga solver
    'solver': ['liblinear', 'saga', 'lbfgs'],
    'max_iter': [100, 200, 300]  # Number of iterations
}

# Set up GridSearchCV
grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)

# Fit the model to the training data
grid_search.fit(X_train, y_train)

# Best parameters from Grid Search
print("Best Parameters:", grid_search.best_params_)

# Best cross-validation accuracy
print("Best Cross-Validation Accuracy:", grid_search.best_score_)

# Use the best estimator to predict on the test set
best_model = grid_search.best_estimator_
test_predictions = best_model.predict(X_test)

# Evaluate the model on the test set
test_accuracy = accuracy_score(y_test, test_predictions)
print("Test Set Accuracy with Best Parameters:", test_accuracy)

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, test_predictions)
print("Confusion Matrix with Best Parameters:")
print(conf_matrix)

# Classification Report
class_report = classification_report(y_test, test_predictions)
print("Classification Report with Best Parameters:")
print(class_report)